{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Geographic Data Handling\n",
    "import geopandas as gpd \n",
    "from geopandas.tools import sjoin\n",
    "from vt2geojson.tools import vt_bytes_to_geojson  \n",
    "from shapely.geometry import Point, box\n",
    "from scipy.spatial import cKDTree \n",
    "import osmnx as ox  \n",
    "import mercantile  \n",
    "\n",
    "# File and Directory Operations\n",
    "import os \n",
    "\n",
    "# Image Processing and Analysis\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation  \n",
    "from scipy.signal import find_peaks \n",
    "import torch  \n",
    "from PIL import Image  \n",
    "import requests  \n",
    "\n",
    "# Libraries for Concurrency and File Manipulation\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed \n",
    "import threading\n",
    "\n",
    "# Time and Date Handling\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Progress Tracking\n",
    "from tqdm.auto import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "filepath = \"C:/Users/ygrin/Documents/Studie - MSc ADS/Utrecht University/Block 4 - Thesis/TestData/\"\n",
    "multi_point_file = filepath+\"Test_multiple_home_locations.gpkg\"\n",
    "single_point_file = filepath+\"Test_single_home_location.gpkg\"\n",
    "results_path = \"C:/Users/ygrin/Documents/Studie - MSc ADS/Utrecht University/Block 4 - Thesis/TestData/Results/\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GVI functions\n",
    "\n",
    "Original code from Ilse A. Vázquez Sánchez: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_road_network_with_points(poi_polygon, epsg):\n",
    "    # Get the road network within the poi polygon\n",
    "    G = ox.graph_from_polygon(poi_polygon, network_type='drive', simplify=True, retain_all=True)\n",
    "\n",
    "    # Create a set to store unique road identifiers\n",
    "    unique_roads = set()\n",
    "    # Create a new graph to store the simplified road network\n",
    "    G_simplified = G.copy()\n",
    "\n",
    "    # Iterate over each road segment\n",
    "    for u, v, key, data in G.edges(keys=True, data=True):\n",
    "        # Check if the road segment is a duplicate\n",
    "        if (v, u) in unique_roads:\n",
    "            # Remove the duplicate road segment\n",
    "            G_simplified.remove_edge(u, v, key)\n",
    "        else:\n",
    "            # Add the road segment to the set of unique roads\n",
    "            unique_roads.add((u, v))\n",
    "    \n",
    "    # Update the graph with the simplified road network\n",
    "    G = G_simplified\n",
    "    \n",
    "    #Project the graph from latitude-longitude coordinates to a local projection (in meters)\n",
    "    G_proj = ox.project_graph(G, to_crs=f\"EPSG:{epsg}\")\n",
    "\n",
    "    # Store graph edges in geodataframe\n",
    "    edges = ox.graph_to_gdfs(G_proj, nodes=False, edges=True)\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "# Get a list of points over the road map with a N distance between them\n",
    "def select_points_on_road_network(roads, N=50):\n",
    "    points = []\n",
    "    # Iterate over each road\n",
    "    \n",
    "    for row in roads.itertuples(index=True, name='Road'):\n",
    "        # Get the LineString object from the geometry\n",
    "        linestring = row.geometry\n",
    "\n",
    "        # Calculate the distance along the linestring and create points every 50 meters\n",
    "        for distance in range(0, int(linestring.length), N):\n",
    "            # Get the point on the road at the current position\n",
    "            point = linestring.interpolate(distance)\n",
    "\n",
    "            # Add the curent point to the list of points\n",
    "            points.append(point)\n",
    "    \n",
    "    # Convert the list of points to a GeoDataFrame\n",
    "    gdf_points = gpd.GeoDataFrame(geometry=points)\n",
    "\n",
    "    # Set the same CRS as the road dataframes for the points dataframe\n",
    "    gdf_points.set_crs(roads.crs, inplace=True)\n",
    "\n",
    "    # Drop duplicate rows based on the geometry column\n",
    "    gdf_points = gdf_points.drop_duplicates(subset=['geometry'])\n",
    "    gdf_points = gdf_points.reset_index(drop=True)\n",
    "\n",
    "    return gdf_points\n",
    "\n",
    "\n",
    "def select_points_within_buffers(poi, road_points):\n",
    "    points_within_buffers = sjoin(road_points, poi.set_geometry('buffer'), how='inner', predicate='within')\n",
    "\n",
    "    # Get the unique points that fall within any buffer\n",
    "    unique_points = points_within_buffers['geometry_left'].unique()\n",
    "\n",
    "    # Create a new GeoDataFrame with the points that fall within any buffer\n",
    "    return gpd.GeoDataFrame(geometry=[Point(p.x, p.y) for p in unique_points], crs=poi.crs)\n",
    "\n",
    "\n",
    "def get_features_for_tile(tile, access_token):\n",
    "    tile_url = f\"https://tiles.mapillary.com/maps/vtp/mly1_public/2/{tile.z}/{tile.x}/{tile.y}?access_token={access_token}\"\n",
    "    response = requests.get(tile_url)\n",
    "    result = vt_bytes_to_geojson(response.content, tile.x, tile.y, tile.z, layer=\"image\")\n",
    "    return [tile, result]\n",
    "\n",
    "\n",
    "def get_features_on_points(buffer_points, access_token, epsg, max_distance=100, zoom=14):\n",
    "    # Transform the coordinate reference system to EPSG 4326\n",
    "    buffer_points_wgs = buffer_points.copy(deep=True).to_crs(epsg=4326)\n",
    "\n",
    "    # Add a new column to gdf_points that contains the tile coordinates for each point\n",
    "    buffer_points[\"tile\"] = [mercantile.tile(x, y, zoom) for x, y in zip(buffer_points_wgs.geometry.x, buffer_points_wgs.geometry.y)]\n",
    "\n",
    "    # Group the points by their corresponding tiles\n",
    "    groups = buffer_points.groupby(\"tile\")\n",
    "\n",
    "    # Download the tiles and extract the features for each group\n",
    "    features = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "\n",
    "        for tile, _ in groups:\n",
    "            futures.append(executor.submit(get_features_for_tile, tile, access_token))\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading tiles\"):\n",
    "            result = future.result()\n",
    "            features.append(result)\n",
    "\n",
    "    pd_features = pd.DataFrame(features, columns=[\"tile\", \"features\"])\n",
    "\n",
    "    # Compute distances between each feature and all the points in gdf_points\n",
    "    feature_points = gpd.GeoDataFrame(\n",
    "        [(Point(f[\"geometry\"][\"coordinates\"]), f) for row in pd_features[\"features\"] for f in row[\"features\"]],\n",
    "        columns=[\"geometry\", \"feature\"],\n",
    "        geometry=\"geometry\",\n",
    "        crs=4326\n",
    "    )\n",
    "\n",
    "    # Transform from EPSG:4326 (world °) to EPSG of poi file\n",
    "    feature_points.to_crs(f\"EPSG:{epsg}\", inplace=True)\n",
    "\n",
    "    feature_tree = cKDTree(feature_points[\"geometry\"].apply(lambda p: [p.x, p.y]).tolist())\n",
    "    distances, indices = feature_tree.query(buffer_points[\"geometry\"].apply(lambda p: [p.x, p.y]).tolist(), k=1, distance_upper_bound=max_distance)\n",
    "\n",
    "    # Create a list to store the closest features and distances\n",
    "    closest_features = [feature_points.loc[i, \"feature\"] if np.isfinite(distances[idx]) else None for idx, i in enumerate(indices)]\n",
    "    closest_distances = [distances[idx] if np.isfinite(distances[idx]) else None for idx in range(len(distances))]\n",
    "\n",
    "    # Store the closest feature for each point in the \"feature\" column of the points DataFrame\n",
    "    buffer_points[\"feature\"] = closest_features\n",
    "\n",
    "    # Store the distances as a new column in points\n",
    "    buffer_points[\"distance\"] = closest_distances\n",
    "\n",
    "    # Store image id and is panoramic information as part of the dataframe\n",
    "    buffer_points[\"image_id\"] = buffer_points.apply(lambda row: str(row[\"feature\"][\"properties\"][\"id\"]) if row[\"feature\"] else \"\", axis=1)\n",
    "    buffer_points[\"image_id\"] = buffer_points[\"image_id\"].astype(str)\n",
    "    \n",
    "    buffer_points[\"is_panoramic\"] = buffer_points.apply(lambda row: bool(row[\"feature\"][\"properties\"][\"is_pano\"]) if row[\"feature\"] else None, axis=1)\n",
    "    buffer_points[\"is_panoramic\"] = buffer_points[\"is_panoramic\"].astype(bool)\n",
    "\n",
    "    # Convert results to geodataframe\n",
    "    buffer_points[\"tile\"] = buffer_points[\"tile\"].astype(str)\n",
    "\n",
    "    # Save the current index as a column\n",
    "    buffer_points[\"point_id\"] = buffer_points.index\n",
    "\n",
    "    # Reset the index\n",
    "    buffer_points = buffer_points.reset_index(drop=True)\n",
    "    \n",
    "    return buffer_points\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "    # setting device on GPU if available, else CPU\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "    model = model.to(device)\n",
    "    return processor, model\n",
    "\n",
    "\n",
    "def run_length_encoding(in_array):\n",
    "    image_array = np.asarray(in_array)\n",
    "    length = len(image_array)\n",
    "    if length == 0: \n",
    "        return (None, None, None)\n",
    "    else:\n",
    "        pairwise_unequal = image_array[1:] != image_array[:-1]\n",
    "        change_points = np.append(np.where(pairwise_unequal), length - 1)   # must include last element posi\n",
    "        run_lengths = np.diff(np.append(-1, change_points))       # run lengths\n",
    "        return(run_lengths, image_array[change_points])\n",
    "\n",
    "\n",
    "def get_road_pixels_per_column(prediction):\n",
    "    road_pixels = prediction == 0.0 # The label for the roads is 0\n",
    "    road_pixels_per_col = np.zeros(road_pixels.shape[1])\n",
    "    \n",
    "    for i in range(road_pixels.shape[1]):\n",
    "        run_lengths, values = run_length_encoding(road_pixels[:,i])\n",
    "        road_pixels_per_col[i] = run_lengths[values.nonzero()].max(initial=0)\n",
    "    return road_pixels_per_col\n",
    "\n",
    "\n",
    "def get_road_centres(prediction, distance=2000, prominence=100):\n",
    "    road_pixels_per_col = get_road_pixels_per_column(prediction)\n",
    "    peaks, _ = find_peaks(road_pixels_per_col, distance=distance, prominence=prominence)\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def find_road_centre(segmentation):\n",
    "\tdistance = int(2000 * segmentation.shape[1] // 5760)\n",
    "\tprominence = int(100 * segmentation.shape[0] // 2880)\n",
    "\t\n",
    "\tcentres = get_road_centres(segmentation, distance=distance, prominence=prominence)\n",
    "\t\n",
    "\treturn centres\n",
    "\n",
    "\n",
    "def crop_panoramic_images(original_width, image, segmentation, road_centre):\n",
    "    width, height = image.size\n",
    "\n",
    "    # Find duplicated centres\n",
    "    duplicated_centres = [centre - original_width for centre in road_centre if centre >= original_width]\n",
    "            \n",
    "    # Drop the duplicated centres\n",
    "    road_centre = [centre for centre in road_centre if centre not in duplicated_centres]\n",
    "\n",
    "    # Calculate dimensions and offsets\n",
    "    w4 = int(width / 4) # \n",
    "    h4 = int(height / 4)\n",
    "    hFor43 = int(w4 * 3 / 4)\n",
    "    w98 = width + (w4 / 2)\n",
    "    xrapneeded = int(width * 7 / 8)\n",
    "\n",
    "    pickles = []\n",
    "    # Crop the panoramic image\n",
    "    for centre in road_centre:\n",
    "        # Wrapped all the way around\n",
    "        if centre >= w98:\n",
    "            xlo = int(centre - w4/2)\n",
    "            cropped_image = image.crop((xlo, h4,  xlo+w4, h4 + hFor43))\n",
    "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
    "        \n",
    "        # Image requires assembly of two sides\n",
    "        elif centre > xrapneeded:\n",
    "            xlo = int(centre - (w4/2)) # horizontal_offset\n",
    "            w4_p1 = width - xlo\n",
    "            w4_p2 = w4 - w4_p1\n",
    "            cropped_image_1 = image.crop((xlo, h4, xlo + w4_p1, h4 + hFor43))\n",
    "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
    "\n",
    "            cropped_image = Image.new(image.mode, (w4, hFor43))\n",
    "            cropped_image.paste(cropped_image_1, (0, 0))\n",
    "            cropped_image.paste(cropped_image_2, (w4_p1, 0))\n",
    "\n",
    "            cropped_segmentation_1 = segmentation[h4:h4+hFor43, xlo:xlo+w4_p1]\n",
    "            cropped_segmentation_2 = segmentation[h4:h4+hFor43, 0:w4_p2]\n",
    "            cropped_segmentation = torch.cat((cropped_segmentation_1, cropped_segmentation_2), dim=1)\n",
    "        \n",
    "        # Must paste together the two sides of the image\n",
    "        elif centre < (w4 / 2):\n",
    "            w4_p1 = int((w4 / 2) - centre)\n",
    "            xhi = width - w4_p1\n",
    "            w4_p2 = w4 - w4_p1\n",
    "\n",
    "            cropped_image_1 = image.crop((xhi, h4, xhi + w4_p1, h4 + hFor43))\n",
    "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
    "\n",
    "            cropped_image = Image.new(image.mode, (w4, hFor43))\n",
    "            cropped_image.paste(cropped_image_1, (0, 0))\n",
    "            cropped_image.paste(cropped_image_2, (w4_p1, 0))\n",
    "\n",
    "            cropped_segmentation_1 = segmentation[h4:h4+hFor43, xhi:xhi+w4_p1]\n",
    "            cropped_segmentation_2 = segmentation[h4:h4+hFor43, 0:w4_p2]\n",
    "            cropped_segmentation = torch.cat((cropped_segmentation_1, cropped_segmentation_2), dim=1)\n",
    "            \n",
    "        # Straightforward crop\n",
    "        else:\n",
    "            xlo = int(centre - w4/2)\n",
    "            cropped_image = image.crop((xlo, h4, xlo + w4, h4 + hFor43))\n",
    "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
    "\n",
    "        pickles.append(cropped_segmentation)\n",
    "\n",
    "    return pickles\n",
    "\n",
    "\n",
    "def segment_images(image, processor, model):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to('cuda') for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            segmentation = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0].to('cpu')\n",
    "        else:\n",
    "            outputs = model(**inputs)\n",
    "            segmentation = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "            \n",
    "    return segmentation\n",
    "\n",
    "\n",
    "def get_GVI(segmentations):\n",
    "    green_percentage = 0\n",
    "    for segment in segmentations:\n",
    "        total_pixels = segment.numel()\n",
    "        vegetation_pixels = (segment == 8).sum().item()\n",
    "        green_percentage += vegetation_pixels / total_pixels\n",
    "    \n",
    "    return green_percentage / len(segmentations)\n",
    "\n",
    "\n",
    "def process_images(image_url, is_panoramic, processor, model):\n",
    "    try:\n",
    "        image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "        if is_panoramic:\n",
    "            # Get the size of the image\n",
    "            width, height = image.size\n",
    "\n",
    "            # Crop the bottom 20% of the image to cut the band on the bottom of the panoramic image\n",
    "            bottom_crop = int(height * 0.2)\n",
    "            image = image.crop((0, 0, width, height - bottom_crop))\n",
    "\n",
    "        # Image segmentation\n",
    "        segmentation = segment_images(image, processor, model)\n",
    "\n",
    "        if is_panoramic:\n",
    "            # Create a widened panorama by wrapping the first 25% of the image onto the right edge\n",
    "            width, height = image.size\n",
    "            w4 = int(0.25 * width)\n",
    "\n",
    "            segmentation_25 = segmentation[:, :w4]\n",
    "            # Concatenate the tensors along the first dimension (rows)\n",
    "            segmentation_road = torch.cat((segmentation, segmentation_25), dim=1)\n",
    "        else:\n",
    "            segmentation_road = segmentation\n",
    "        \n",
    "        # Find roads to determine if the image is suitable for the analysis or not AND crop the panoramic images\n",
    "        road_centre = find_road_centre(segmentation_road)\n",
    "\n",
    "        if len(road_centre) > 0:\n",
    "            if is_panoramic:\n",
    "                pickles = crop_panoramic_images(width, image, segmentation_road, road_centre)\n",
    "            else:\n",
    "                pickles = [segmentation]\n",
    "        \n",
    "            # Now we can get the Green View Index\n",
    "            GVI = get_GVI(pickles)\n",
    "            return [GVI, is_panoramic, False, False]\n",
    "        else:\n",
    "            # There are not road centres, so the image is unusable\n",
    "            return [None, None, True, False]\n",
    "    except:\n",
    "        return [None, None, True, True]\n",
    "\n",
    "def download_image(id, geometry, image_id, is_panoramic, access_token, processor, model):\n",
    "    if image_id:\n",
    "        try:\n",
    "            header = {'Authorization': 'OAuth {}'.format(access_token)}\n",
    "        \n",
    "            url = 'https://graph.mapillary.com/{}?fields=thumb_original_url'.format(image_id)\n",
    "            response = requests.get(url, headers=header)\n",
    "            data = response.json()\n",
    "            image_url = data[\"thumb_original_url\"]\n",
    "\n",
    "            result = process_images(image_url, is_panoramic, processor, model)\n",
    "        except:\n",
    "            # There was an error during the downloading of the image\n",
    "            result = [None, None, True, True]\n",
    "    else:\n",
    "        # The point doesn't have an image, then we set the missing value to true\n",
    "        result = [None, None, True, False]\n",
    "    \n",
    "    result.insert(0, geometry)\n",
    "    result.insert(0, id)\n",
    "\n",
    "    return result\n",
    "    \n",
    "\n",
    "def download_images_for_points(gdf, access_token, epsg, max_workers=4):\n",
    "    processor, model = get_models()\n",
    "    gdf_wgs = gdf.copy(deep=True).to_crs(\"EPSG:4326\")\n",
    "    # Create a lock object\n",
    "    results = []\n",
    "    lock = threading.Lock()\n",
    "        \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "\n",
    "        for _, row in gdf_wgs.iterrows():\n",
    "            try:\n",
    "                futures.append(executor.submit(download_image, row[\"point_id\"], row[\"geometry\"], row[\"image_id\"], row[\"is_panoramic\"], access_token, processor, model))\n",
    "            except Exception as e:\n",
    "                print(f\"Exception occurred for row {row['id']}: {str(e)}\")\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Downloading images\"):\n",
    "            image_result = future.result()\n",
    "\n",
    "            # Acquire the lock before appending to results\n",
    "            with lock:\n",
    "                results.append(image_result)\n",
    "        \n",
    "    # Combine the results from all parts\n",
    "    final_results = gpd.GeoDataFrame(results, columns=[\"point_id\", \"geometry\", \"GVI\", \"is_panoramic\", \"missing\", \"error\"], crs=\"EPSG:4326\").to_crs(f\"EPSG:{epsg}\")\n",
    "    \n",
    "    return final_results\n",
    "\n",
    "def get_gvi_per_buffer(buffered_points, gvi_per_point):\n",
    "    joined = gpd.sjoin(gvi_per_point, buffered_points.set_geometry('buffer'), how='inner', predicate='within').drop('index_right', axis=1)\n",
    "\n",
    "    # Group the points by buffer\n",
    "    grouped = joined.groupby('id', group_keys=True)\n",
    "    # Convert 'grouped' to a DataFrame\n",
    "    grouped_df = grouped.apply(lambda x: x.reset_index(drop=True))\n",
    "    grouped_df = grouped_df[[\"geometry_left\", \"GVI\", \"is_panoramic\", \"missing\"]].reset_index()\n",
    "    # Convert grouped_df to a GeoDataFrame\n",
    "    grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry_left').rename(columns={'geometry_left':'geometry'}).drop('level_1', axis=1)\n",
    "    grouped_gdf = grouped_gdf.set_geometry('geometry')\n",
    "    # Calculate the average 'gvi' for each group\n",
    "    avg_gvi = grouped['GVI'].mean().reset_index()\n",
    "    nr_of_points = grouped['GVI'].count().reset_index(name='nr_of_points')\n",
    "    # Merge with the buffered_points dataframe to get the buffer geometries\n",
    "    result = avg_gvi.merge(buffered_points, left_on='id', right_on='id')\n",
    "    result = result.merge(nr_of_points, on='id')\n",
    "    # Convert the result to a GeoDataFrame\n",
    "    result = gpd.GeoDataFrame(result[['id', 'geometry', 'GVI', 'nr_of_points']])\n",
    "\n",
    "    return result, grouped_gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top level function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streetview_GVI(point_of_interest_file, access_token=None, crs_epsg=None, polygon_type=\"neighbourhood\", buffer_dist=None, workers=4,\n",
    "                       network_file=None, write_to_file=True, output_dir=os.getcwd()):\n",
    "    \n",
    "    ### Step 1: Read and process user inputs, check conditions\n",
    "    poi = gpd.read_file(point_of_interest_file)\n",
    "    # Make sure geometries of poi file are either all provided using point geometries or all using polygon geometries\n",
    "    if all(poi['geometry'].geom_type == 'Point') or all(poi['geometry'].geom_type == 'Polygon'):\n",
    "        geom_type = poi.iloc[0]['geometry'].geom_type\n",
    "    else:\n",
    "        raise ValueError(\"Please make sure all geometries are of 'Point' type or all geometries are of 'Polygon' type and re-run the function\")\n",
    "\n",
    "    # Make sure CRS of poi file is projected rather than geographic\n",
    "    if not poi.crs.is_projected:\n",
    "        if crs_epsg is None:\n",
    "            print(\"Warning: The CRS of the PoI dataset is currently geographic, therefore it will now be projected to CRS with EPSG:3395\")\n",
    "            epsg = 3395\n",
    "            poi.to_crs(f\"EPSG:{epsg}\", inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: The CRS of the PoI dataset is currently geographic, therefore it will now be projected to EPSG:{crs_epsg} as specified\")\n",
    "            epsg = crs_epsg\n",
    "            poi.to_crs(f\"EPSG:{epsg}\", inplace=True)\n",
    "    else:\n",
    "        epsg = poi.crs.to_epsg()\n",
    "\n",
    "    # In case of house polygons, transform to centroids\n",
    "    if geom_type == \"Polygon\":\n",
    "        if polygon_type not in [\"neighbourhood\", \"house\"]:\n",
    "            raise TypeError(\"Please make sure that the polygon_type argument is set to either 'neighbourhood' or 'house'\")\n",
    "        if polygon_type == \"house\":\n",
    "            print(\"Changing geometry type to Point by computing polygon centroids...\")\n",
    "            poi['geometry'] = poi['geometry'].centroid\n",
    "            geom_type = poi.iloc[0]['geometry'].geom_type\n",
    "            print(\"Done \\n\")\n",
    "\n",
    "    # Make sure poi dataframe has id column\n",
    "    if \"id\" in poi.columns:\n",
    "        if poi['id'].isnull().values.any():\n",
    "            poi['id'] = poi['id'].fillna(pd.Series(range(1, len(poi) + 1))).astype(int)\n",
    "    else:\n",
    "        poi['id'] = pd.Series(range(1, len(poi) + 1)).astype(int)\n",
    "\n",
    "    # Make sure buffer distance is set in case geometries of poi file are of point type\n",
    "    if geom_type == \"Point\":\n",
    "        if not isinstance(buffer_dist, int) or (not buffer_dist > 0):\n",
    "            raise TypeError(\"Please make sure that the buffer_dist argument is set to a positive integer\")\n",
    "\n",
    "    # Make sure Mapillary API token is provided\n",
    "    if access_token is None or not access_token.startswith(\"MLY\"):\n",
    "        raise TypeError(\"Please make sure that a valid access token for Mapillary is provided\")\n",
    "\n",
    "    # Make sure number of workers is valid value\n",
    "    if not isinstance(workers, int) or (not workers > 0):\n",
    "        raise TypeError(\"Please make sure that the workers argument is set to a positive integer\")\n",
    "    \n",
    "    # Determine area of interest by taking bounding box of poi file, incl. buffer if specified\n",
    "    if buffer_dist is None:\n",
    "        poi_polygon = box(*poi.total_bounds)\n",
    "        poi['buffer'] = poi['geometry']\n",
    "    else:\n",
    "        poi_polygon = box(*poi.total_bounds).buffer(buffer_dist)\n",
    "        poi['buffer'] = poi['geometry'].buffer(buffer_dist)\n",
    "    # Transform to 4326 for OSM\n",
    "    polygon_gdf_wgs = gpd.GeoDataFrame(geometry=[poi_polygon], crs=f\"EPSG:{epsg}\").to_crs(\"EPSG:4326\") \n",
    "    # Extract polygon in EPSG 4326\n",
    "    wgs_polygon = polygon_gdf_wgs['geometry'].values[0] \n",
    "\n",
    "    if network_file is not None:\n",
    "        # Make sure network file is either provided as geopackage or shapefile\n",
    "        if os.path.splitext(network_file)[1] not in [\".gpkg\", \".shp\"]:\n",
    "            raise ValueError(\"Please provide the network file in '.gpkg' or '.shp' format\")\n",
    "        elif network_file is not None and (os.path.splitext(network_file)[1] == \".gpkg\"):\n",
    "            network_edges = gpd.read_file(network_file, layer='edges')\n",
    "        else: \n",
    "            network_edges = gpd.read_file(network_file)\n",
    "\n",
    "        # Make sure network file CRS is same as CRS of poi file\n",
    "        if not network_edges.crs.to_epsg() == epsg:\n",
    "            print(\"Adjusting CRS of Network file to match with Point of Interest CRS...\")\n",
    "            network_edges.to_crs(f'EPSG:{epsg}', inplace=True)\n",
    "            print(\"Done \\n\")\n",
    "\n",
    "        # Check if house locations are within network file provided\n",
    "        bbox_network = network_edges.unary_union.envelope\n",
    "        if not all(geom.within(bbox_network) for geom in poi['geometry']):\n",
    "            raise ValueError(\"Not all points of interest are within the network file provided, please make sure they are and re-run the function\")\n",
    "    else:\n",
    "        print(f\"Retrieving network within total bounds of {geom_type}(s) of interest, extended by the buffer_dist in case provided...\")\n",
    "        start_network_retrieval = time()\n",
    "        # Extract network from OpenStreetMap\n",
    "        network_edges = get_road_network_with_points(wgs_polygon, epsg=epsg)\n",
    "        end_network_retrieval = time()\n",
    "        elapsed_network_retrieval = end_network_retrieval - start_network_retrieval\n",
    "        print(f\"Done, running time: {str(timedelta(seconds=elapsed_network_retrieval))} \\n\")\n",
    "\n",
    "    print(\"Computing sample points for roads within area of interest's network...\")\n",
    "    start_sample_points = time()\n",
    "    # Get sample points on network roads\n",
    "    road_points = select_points_on_road_network(network_edges)\n",
    "    # Filter points to maintain the ones that are within the buffers of the poi geometries\n",
    "    buffer_points = select_points_within_buffers(poi, road_points)\n",
    "    # Check if any road sample points are found within specified buffer distance\n",
    "    if len(buffer_points) == 0:\n",
    "        raise ValueError(\"No road locations could be retrieved within the buffer distance set, please increase the buffer distance and re-run the function\")\n",
    "    end_sample_points = time()\n",
    "    elapsed_sample_points = end_sample_points - start_sample_points\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_sample_points))} \\n\")\n",
    "    \n",
    "    print(\"Downloading StreetView images for road sample points...\")\n",
    "    start_images = time()\n",
    "    # Retrieve features, images, from Mapillary for the road locations\n",
    "    features = get_features_on_points(buffer_points, access_token, epsg)\n",
    "    # Process the features and calculate GVI score for road locations\n",
    "    gvi_per_point = download_images_for_points(features, access_token, epsg, workers)\n",
    "    end_images = time()\n",
    "    elapsed_images = end_images - start_images\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_images))} \\n\")\n",
    "    \n",
    "    print(\"Calculating StreetView GVI score...\")\n",
    "    start_calc = time()\n",
    "    # Calculate average GVI for each geometry in poi dataframe\n",
    "    poi, sampled_points_gdf = get_gvi_per_buffer(poi, gvi_per_point)\n",
    "    end_calc = time()\n",
    "    elapsed_calc = end_calc - start_calc\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_calc))} \\n\")\n",
    "\n",
    "    print(\"Note: workflow for calculating Streetview GVI based on code by Ilse A. Vázquez Sánchez \\nsource: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility \\n\")\n",
    "    \n",
    "    if write_to_file:\n",
    "        print(\"Writing results to new geopackage file in specified directory...\")\n",
    "        # Create output directory if the one specified by user does not yet exist\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        # Extract filename of poi file to add information when writing to file\n",
    "        input_filename, _ = os.path.splitext(os.path.basename(point_of_interest_file))\n",
    "        poi.to_file(os.path.join(output_dir, f\"{input_filename}_StreetviewGVI_added.gpkg\"), driver=\"GPKG\")\n",
    "        sampled_points_gdf.to_file(os.path.join(output_dir, f\"{input_filename}_StreetviewGVI_sampled_points.gpkg\"), driver=\"GPKG\")\n",
    "        print(\"Done\")\n",
    "\n",
    "    return poi, sampled_points_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving network within total bounds of Point(s) of interest, extended by the buffer_dist in case provided...\n",
      "Done, running time: 0:00:08.499444 \n",
      "\n",
      "Computing sample points for roads within area of interest's network...\n",
      "Done, running time: 0:00:00.447860 \n",
      "\n",
      "Downloading StreetView images for road sample points...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tiles: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n",
      "Downloading images: 100%|██████████| 200/200 [16:41<00:00,  5.01s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, running time: 0:16:53.875847 \n",
      "\n",
      "Calculating StreetView GVI score...\n",
      "Done, running time: 0:00:00.181536 \n",
      "\n",
      "Note: workflow for calculating Streetview GVI based on code by Ilse A. Vázquez Sánchez \n",
      "source: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility \n",
      "\n",
      "Writing results to new geopackage file in specified directory...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "poi, sampled_points_gdf = get_streetview_GVI(point_of_interest_file=multi_point_file,\n",
    "                                             access_token=\"MAPILLARY_API_TOKEN\", \n",
    "                                             crs_epsg=None, \n",
    "                                             polygon_type=\"neighbourhood\", \n",
    "                                             buffer_dist=250, \n",
    "                                             write_to_file=True, \n",
    "                                             output_dir=results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GVI</th>\n",
       "      <th>nr_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388644.249 392861.634)</td>\n",
       "      <td>0.273109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (385981.911 393805.494)</td>\n",
       "      <td>0.234678</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388631.230 395322.181)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       geometry       GVI  nr_of_points\n",
       "0   1  POINT (388644.249 392861.634)  0.273109             1\n",
       "1   2  POINT (385981.911 393805.494)  0.234678            32\n",
       "2   3  POINT (388631.230 395322.181)       NaN             0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GVI</th>\n",
       "      <th>is_panoramic</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388476.455 393032.843)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388492.190 393025.144)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388482.733 392976.636)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388432.330 392873.765)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>POINT (388481.867 392880.021)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388473.612 395249.288)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388575.466 395143.667)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388615.413 395113.597)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388421.262 395192.073)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388416.839 395241.783)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                       geometry  GVI is_panoramic  missing\n",
       "0     1  POINT (388476.455 393032.843)  NaN         None     True\n",
       "1     1  POINT (388492.190 393025.144)  NaN         None     True\n",
       "2     1  POINT (388482.733 392976.636)  NaN         None     True\n",
       "3     1  POINT (388432.330 392873.765)  NaN         None     True\n",
       "4     1  POINT (388481.867 392880.021)  NaN         None     True\n",
       "..   ..                            ...  ...          ...      ...\n",
       "195   3  POINT (388473.612 395249.288)  NaN         None     True\n",
       "196   3  POINT (388575.466 395143.667)  NaN         None     True\n",
       "197   3  POINT (388615.413 395113.597)  NaN         None     True\n",
       "198   3  POINT (388421.262 395192.073)  NaN         None     True\n",
       "199   3  POINT (388416.839 395241.783)  NaN         None     True\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_points_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
