{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Analysis\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "# Geographic Data Handling\n",
    "import geopandas as gpd \n",
    "from geopandas.tools import sjoin\n",
    "from vt2geojson.tools import vt_bytes_to_geojson  \n",
    "from shapely.geometry import Point, box\n",
    "from scipy.spatial import cKDTree \n",
    "import osmnx as ox  \n",
    "import mercantile  \n",
    "\n",
    "# File and Directory Operations\n",
    "import os \n",
    "\n",
    "# Image Processing and Analysis\n",
    "from transformers import AutoImageProcessor, Mask2FormerForUniversalSegmentation  \n",
    "from scipy.signal import find_peaks \n",
    "import torch  \n",
    "from PIL import Image  \n",
    "import requests  \n",
    "\n",
    "# Libraries for Concurrency and File Manipulation\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed \n",
    "import multiprocessing as mp \n",
    "\n",
    "# Time and Date Handling\n",
    "from time import time\n",
    "from datetime import timedelta\n",
    "\n",
    "# Progress Tracking\n",
    "from tqdm import tqdm  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data\n",
    "test_path = \"C:/Users/ygrin/Documents/Studie - MSc ADS/Utrecht University/Block 4 - Thesis/TestData/\"\n",
    "test_results_path = \"C:/Users/ygrin/Documents/Studie - MSc ADS/Utrecht University/Block 4 - Thesis/TestData/Results/\"\n",
    "single_point = gpd.read_file(test_path + \"Test_single_home_location.gpkg\")\n",
    "multi_point = gpd.read_file(test_path + \"Test_multiple_home_locations.gpkg\")\n",
    "polygon = gpd.read_file(test_path + \"test_polygon.gpkg\")\n",
    "\n",
    "# USER NETWORK\n",
    "network = gpd.read_file(test_path + \"test_network_shp.shp\").to_crs('EPSG:27700')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GVI functions\n",
    "\n",
    "Original code from Ilse A. Vázquez Sánchez: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_road_network_with_points(poi_polygon, epsg):\n",
    "    # Get the road network within the bounding box\n",
    "    G = ox.graph_from_polygon(poi_polygon, network_type='drive', simplify=True)\n",
    "\n",
    "    #Project the graph from latitude-longitude coordinates to a local projection (in meters)\n",
    "    G_proj = ox.project_graph(G, to_crs=f\"EPSG:{epsg}\")\n",
    "\n",
    "    # Convert the projected graph to a GeoDataFrame\n",
    "    edges = ox.graph_to_gdfs(G_proj, nodes=False, edges=True)\n",
    "\n",
    "    return edges\n",
    "\n",
    "\n",
    "# Get a list of points over the road map with a N distance between them\n",
    "def select_points_on_road_network(network_edges, distance=50):\n",
    "    # Initialize a list to store the points\n",
    "    points = []\n",
    "\n",
    "    # Loop through each road in the road network graph\n",
    "    for road in network_edges.geometry:\n",
    "        # Calculate the total length of the road\n",
    "        road_length = road.length\n",
    "\n",
    "        # Start at the beginning of the road\n",
    "        current_position = 0\n",
    "\n",
    "        # Loop through the road, adding points every 50 meters\n",
    "        while current_position < road_length:\n",
    "            # Get the point on the road at the current position\n",
    "            current_point = road.interpolate(current_position)\n",
    "\n",
    "            # Add the curent point to the list of points\n",
    "            points.append(current_point)\n",
    "\n",
    "            # Increment the position by the desired distance\n",
    "            current_position += distance\n",
    "    \n",
    "    # Convert the list of points to a GeoDataFrame\n",
    "    gdf_points = gpd.GeoDataFrame(geometry=points, crs=network_edges.crs)\n",
    "\n",
    "    return gdf_points\n",
    "\n",
    "\n",
    "def select_points_within_buffers(poi, road_points):\n",
    "    points_within_buffers = sjoin(road_points, poi.set_geometry('buffer'), how='inner', predicate='within')\n",
    "\n",
    "    # Get the unique points that fall within any buffer\n",
    "    unique_points = points_within_buffers['geometry_left'].unique()\n",
    "\n",
    "    # Create a new GeoDataFrame with the points that fall within any buffer\n",
    "    return gpd.GeoDataFrame(geometry=[Point(p.x, p.y) for p in unique_points], crs=poi.crs)\n",
    "\n",
    "\n",
    "def get_features_for_tile(tile, access_token):\n",
    "    tile_url = f\"https://tiles.mapillary.com/maps/vtp/mly1_public/2/{tile.z}/{tile.x}/{tile.y}?access_token={access_token}\"\n",
    "    response = requests.get(tile_url)\n",
    "    result = vt_bytes_to_geojson(response.content, tile.x, tile.y, tile.z, layer=\"image\")\n",
    "    return [tile, result]\n",
    "\n",
    "\n",
    "def get_features_on_points(buffer_points, access_token, zoom=14):\n",
    "    # Transform the coordinate reference system to EPSG 4326\n",
    "    buffer_points_wgs = buffer_points.copy(deep=True).to_crs(epsg=4326)\n",
    "\n",
    "    # Add a new column to gdf_points that contains the tile coordinates for each point\n",
    "    buffer_points['tile'] = [mercantile.tile(x, y, zoom) for x, y in zip(buffer_points_wgs.geometry.x, buffer_points_wgs.geometry.y)]\n",
    "\n",
    "    # Group the points by their corresponding tiles\n",
    "    groups = buffer_points.groupby('tile')\n",
    "\n",
    "    # Download the tiles and extract the features for each group\n",
    "    features = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=10) as executor:\n",
    "        futures = []\n",
    "\n",
    "        for tile, _ in groups:\n",
    "            futures.append(executor.submit(get_features_for_tile, tile, access_token))\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Downloading tiles\"):\n",
    "            result = future.result()\n",
    "            features.append(result)\n",
    "\n",
    "    pd_features = pd.DataFrame(features, columns=[\"tile\", \"features\"])\n",
    "\n",
    "    # Compute distances between each feature and all the points in gdf_points\n",
    "    feature_points = pd.DataFrame(\n",
    "        [(Point(f[\"geometry\"][\"coordinates\"]), f) for row in pd_features[\"features\"] for f in row[\"features\"]],\n",
    "        columns=[\"geometry\", \"feature\"]\n",
    "    )\n",
    "    feature_tree = cKDTree(feature_points[\"geometry\"].apply(lambda p: [p.x, p.y]).tolist())\n",
    "    _, indices = feature_tree.query(buffer_points_wgs[\"geometry\"].apply(lambda p: [p.x, p.y]).tolist())\n",
    "\n",
    "    # Select the closest feature for each point\n",
    "    buffer_points[\"feature\"] = feature_points.loc[indices, \"feature\"].tolist()\n",
    "\n",
    "    # Convert results to geodataframe\n",
    "    buffer_points['tile'] = buffer_points['tile'].astype(str)\n",
    "    \n",
    "    return buffer_points\n",
    "\n",
    "\n",
    "def get_models():\n",
    "    processor = AutoImageProcessor.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "    model = Mask2FormerForUniversalSegmentation.from_pretrained(\"facebook/mask2former-swin-large-cityscapes-semantic\")\n",
    "    return processor, model\n",
    "\n",
    "\n",
    "def run_length_encoding(in_array):\n",
    "    image_array = np.asarray(in_array)\n",
    "    length = len(image_array)\n",
    "    if length == 0: \n",
    "        return (None, None, None)\n",
    "    else:\n",
    "        pairwise_unequal = image_array[1:] != image_array[:-1]\n",
    "        change_points = np.append(np.where(pairwise_unequal), length - 1)   # must include last element posi\n",
    "        run_lengths = np.diff(np.append(-1, change_points))       # run lengths\n",
    "        return(run_lengths, image_array[change_points])\n",
    "\n",
    "\n",
    "def get_road_pixels_per_column(prediction):\n",
    "    road_pixels = prediction == 0.0 # The label for the roads is 0\n",
    "    road_pixels_per_col = np.zeros(road_pixels.shape[1])\n",
    "    \n",
    "    for i in range(road_pixels.shape[1]):\n",
    "        run_lengths, values = run_length_encoding(road_pixels[:,i])\n",
    "        road_pixels_per_col[i] = run_lengths[values.nonzero()].max(initial=0)\n",
    "    return road_pixels_per_col\n",
    "\n",
    "\n",
    "def get_road_centres(prediction, distance=2000, prominence=100):\n",
    "    road_pixels_per_col = get_road_pixels_per_column(prediction)\n",
    "    peaks, _ = find_peaks(road_pixels_per_col, distance=distance, prominence=prominence)\n",
    "    \n",
    "    return peaks\n",
    "\n",
    "\n",
    "def find_road_centre(segmentation):\n",
    "\tdistance = int(2000 * segmentation.shape[1] // 5760)\n",
    "\tprominence = int(100 * segmentation.shape[0] // 2880)\n",
    "\t\n",
    "\tcentres = get_road_centres(segmentation, distance=distance, prominence=prominence)\n",
    "\t\n",
    "\treturn centres\n",
    "\n",
    "\n",
    "def crop_panoramic_images(original_width, image, segmentation, road_centre):\n",
    "    width, height = image.size\n",
    "\n",
    "    # Find duplicated centres\n",
    "    duplicated_centres = [centre - original_width for centre in road_centre if centre >= original_width]\n",
    "            \n",
    "    # Drop the duplicated centres\n",
    "    road_centre = [centre for centre in road_centre if centre not in duplicated_centres]\n",
    "\n",
    "    # Calculate dimensions and offsets\n",
    "    w4 = int(width / 4) # \n",
    "    h4 = int(height / 4)\n",
    "    hFor43 = int(w4 * 3 / 4)\n",
    "    w98 = width + (w4 / 2)\n",
    "    xrapneeded = int(width * 7 / 8)\n",
    "\n",
    "    images = []\n",
    "    pickles = []\n",
    "    # Crop the panoramic image\n",
    "    for centre in road_centre:\n",
    "        # Wrapped all the way around\n",
    "        if centre >= w98:\n",
    "            xlo = int(centre - w4/2)\n",
    "            cropped_image = image.crop((xlo, h4,  xlo+w4, h4 + hFor43))\n",
    "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
    "        \n",
    "        # Image requires assembly of two sides\n",
    "        elif centre > xrapneeded:\n",
    "            xlo = int(centre - (w4/2)) # horizontal_offset\n",
    "            w4_p1 = width - xlo\n",
    "            w4_p2 = w4 - w4_p1\n",
    "            cropped_image_1 = image.crop((xlo, h4, xlo + w4_p1, h4 + hFor43))\n",
    "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
    "\n",
    "            cropped_image = Image.new(image.mode, (w4, hFor43))\n",
    "            cropped_image.paste(cropped_image_1, (0, 0))\n",
    "            cropped_image.paste(cropped_image_2, (w4_p1, 0))\n",
    "\n",
    "            cropped_segmentation_1 = segmentation[h4:h4+hFor43, xlo:xlo+w4_p1]\n",
    "            cropped_segmentation_2 = segmentation[h4:h4+hFor43, 0:w4_p2]\n",
    "            cropped_segmentation = torch.cat((cropped_segmentation_1, cropped_segmentation_2), dim=1)\n",
    "        \n",
    "        # Must paste together the two sides of the image\n",
    "        elif centre < (w4 / 2):\n",
    "            w4_p1 = int((w4 / 2) - centre)\n",
    "            xhi = width - w4_p1\n",
    "            w4_p2 = w4 - w4_p1\n",
    "\n",
    "            cropped_image_1 = image.crop((xhi, h4, xhi + w4_p1, h4 + hFor43))\n",
    "            cropped_image_2 = image.crop((0, h4, w4_p2, h4 + hFor43))\n",
    "\n",
    "            cropped_image = Image.new(image.mode, (w4, hFor43))\n",
    "            cropped_image.paste(cropped_image_1, (0, 0))\n",
    "            cropped_image.paste(cropped_image_2, (w4_p1, 0))\n",
    "\n",
    "            cropped_segmentation_1 = segmentation[h4:h4+hFor43, xhi:xhi+w4_p1]\n",
    "            cropped_segmentation_2 = segmentation[h4:h4+hFor43, 0:w4_p2]\n",
    "            cropped_segmentation = torch.cat((cropped_segmentation_1, cropped_segmentation_2), dim=1)\n",
    "            \n",
    "        # Straightforward crop\n",
    "        else:\n",
    "            xlo = int(centre - w4/2)\n",
    "            cropped_image = image.crop((xlo, h4, xlo + w4, h4 + hFor43))\n",
    "            cropped_segmentation = segmentation[h4:h4+hFor43, xlo:xlo+w4]\n",
    "        \n",
    "        images.append(cropped_image)\n",
    "        pickles.append(cropped_segmentation)\n",
    "\n",
    "    return images, pickles\n",
    "\n",
    "\n",
    "def segment_images(image, processor, model):\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # You can pass them to processor for postprocessing\n",
    "    segmentation = processor.post_process_semantic_segmentation(outputs, target_sizes=[image.size[::-1]])[0]\n",
    "\n",
    "    return segmentation\n",
    "\n",
    "\n",
    "def get_GVI(segmentations):\n",
    "    green_percentage = 0\n",
    "    for segment in segmentations:\n",
    "        total_pixels = segment.numel()\n",
    "        vegetation_pixels = (segment == 8).sum().item()\n",
    "        green_percentage += vegetation_pixels / total_pixels\n",
    "    \n",
    "    return green_percentage / len(segmentations)\n",
    "\n",
    "\n",
    "def process_images(image_url, is_panoramic, processor, model):\n",
    "    try:\n",
    "        image = Image.open(requests.get(image_url, stream=True).raw)\n",
    "\n",
    "        if is_panoramic:\n",
    "            # Get the size of the image\n",
    "            width, height = image.size\n",
    "\n",
    "            # Crop the bottom 20% of the image to cut the band on the bottom of the panoramic image\n",
    "            bottom_crop = int(height * 0.2)\n",
    "            image = image.crop((0, 0, width, height - bottom_crop))\n",
    "\n",
    "        # Image segmentation\n",
    "        segmentation = segment_images(image, processor, model)\n",
    "\n",
    "        if is_panoramic:\n",
    "            # Create a widened panorama by wrapping the first 25% of the image onto the right edge\n",
    "            width, height = image.size\n",
    "            w4 = int(0.25 * width)\n",
    "\n",
    "            segmentation_25 = segmentation[:, :w4]\n",
    "            # Concatenate the tensors along the first dimension (rows)\n",
    "            segmentation_road = torch.cat((segmentation, segmentation_25), dim=1)\n",
    "        else:\n",
    "            segmentation_road = segmentation\n",
    "        \n",
    "        # Find roads to determine if the image is suitable for the analysis or not AND crop the panoramic images\n",
    "        road_centre = find_road_centre(segmentation_road)\n",
    "\n",
    "        if len(road_centre) > 0:\n",
    "            if is_panoramic:\n",
    "                images, pickles = crop_panoramic_images(width, image, segmentation_road, road_centre)\n",
    "            else:\n",
    "                images = [image]\n",
    "                pickles = [segmentation]\n",
    "        \n",
    "            # Now we can get the Green View Index\n",
    "            GVI = get_GVI(pickles)\n",
    "            return [GVI, is_panoramic, False, False]\n",
    "        else:\n",
    "            # There are not road centres, so the image is unusable\n",
    "            return [None, None, True, False]\n",
    "    except:\n",
    "        return [None, None, True, True]\n",
    "\n",
    "\n",
    "def download_image(geometry, image_metadata, access_token, processor, model):\n",
    "    header = {'Authorization': 'OAuth {}'.format(access_token)}\n",
    "\n",
    "    image_id = image_metadata[\"properties\"][\"id\"]\n",
    "    is_panoramic = image_metadata[\"properties\"][\"is_pano\"]\n",
    "    \n",
    "    url = 'https://graph.mapillary.com/{}?fields=thumb_original_url'.format(image_id)\n",
    "    response = requests.get(url, headers=header)\n",
    "    data = response.json()\n",
    "    image_url = data[\"thumb_original_url\"]\n",
    "\n",
    "    result = process_images(image_url, is_panoramic, processor, model)\n",
    "    result.insert(0, geometry)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_data(gdf, access_token, epsg, max_workers=1):\n",
    "    processor, model = get_models()\n",
    "\n",
    "    gdf_wgs = gdf.copy(deep=True).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for _, row in gdf_wgs.iterrows():\n",
    "            feature = row[\"feature\"]\n",
    "            geometry = row[\"geometry\"]\n",
    "            futures.append(executor.submit(download_image, geometry, feature, access_token, processor, model))\n",
    "    \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Downloading images\"):\n",
    "            image_result = future.result()\n",
    "            results.append(image_result)\n",
    "    \n",
    "    images_results_gdf = gpd.GeoDataFrame(results, columns=[\"geometry\", \"GVI\", \"is_panoramic\", \"missing\", \"error\"], crs=\"EPSG:4326\").to_crs(f\"EPSG:{epsg}\")\n",
    "    return images_results_gdf\n",
    "    \n",
    "'''\n",
    "def process_data(index, data_part, processor, model, access_token, max_workers):\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for _, row in data_part.iterrows():\n",
    "            feature = row[\"feature\"]\n",
    "            geometry = row[\"geometry\"]\n",
    "            futures.append(executor.submit(download_image, geometry, feature, access_token, processor, model))\n",
    "    \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Downloading images (Process {index})\"):\n",
    "            image_result = future.result()\n",
    "            results.append(image_result)\n",
    "        return results\n",
    "\n",
    "def process_data(gdf, access_token, epsg, max_workers):\n",
    "    gdf_wgs = gdf.copy(deep=True).to_crs(\"EPSG:4326\")\n",
    "    processor, model = get_models()\n",
    "    results = []\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for _, row in gdf_wgs.iterrows():\n",
    "            feature = row[\"feature\"]\n",
    "            geometry = row[\"geometry\"]\n",
    "            futures.append(executor.submit(download_image, geometry, feature, access_token, processor, model))\n",
    "    \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=f\"Downloading images\"):\n",
    "            image_result = future.result()\n",
    "            results.append(image_result)\n",
    "\n",
    "    images_results_gdf = gpd.GeoDataFrame(results, columns=[\"geometry\", \"GVI\", \"is_panoramic\", \"missing\", \"error\"], crs=\"EPSG:4326\").to_crs(f\"EPSG:{epsg}\")\n",
    "    return images_results_gdf\n",
    "\n",
    "def download_images_for_points(gdf, access_token, epsg, max_workers=1):\n",
    "    processor, model = get_models()\n",
    "    \n",
    "    gdf_wgs = gdf.copy(deep=True).to_crs(\"EPSG:4326\")\n",
    "\n",
    "    images_results = []\n",
    "\n",
    "    # Split the dataset into parts\n",
    "    num_processes = mp.cpu_count()-1 # Get the number of CPU cores\n",
    "    data_parts = np.array_split(gdf_wgs, num_processes) # Split the dataset\n",
    "    \n",
    "    with mp.get_context(\"spawn\").Pool(processes=num_processes) as pool:\n",
    "        # Apply the function to each part of the dataset using multiprocessing\n",
    "        results = pool.starmap(process_data, [(index, data_part, processor, model, access_token, max_workers) for index, data_part in enumerate(data_parts)])\n",
    "\n",
    "        # Combine the results from all parts\n",
    "        images_results = [result for part_result in results for result in part_result]\n",
    "\n",
    "        # Close the pool to release resources\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    images_results_gdf = gpd.GeoDataFrame(images_results, columns=[\"geometry\", \"GVI\", \"is_panoramic\", \"missing\", \"error\"], crs=\"EPSG:4326\").to_crs(f\"EPSG:{epsg}\")\n",
    "    return images_results_gdf\n",
    "'''\n",
    "\n",
    "\n",
    "def get_gvi_per_buffer(buffered_points, gvi_per_point):\n",
    "    joined = gpd.sjoin(gvi_per_point, buffered_points.set_geometry('buffer'), how='inner', predicate='within').drop('index_right', axis=1)\n",
    "    \n",
    "    # Group the points by buffer\n",
    "    grouped = joined.groupby('id', group_keys=True)\n",
    "    # Convert 'grouped' to a DataFrame\n",
    "    grouped_df = grouped.apply(lambda x: x.reset_index(drop=True))\n",
    "    grouped_df = grouped_df[[\"geometry_left\", \"GVI\", \"is_panoramic\", \"missing\"]].reset_index()\n",
    "    # Convert grouped_df to a GeoDataFrame\n",
    "    grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry_left').rename(columns={'geometry_left':'geometry'}).drop('level_1', axis=1)\n",
    "    grouped_gdf = grouped_gdf.set_geometry('geometry')\n",
    "    # Calculate the average 'gvi' for each group\n",
    "    avg_gvi = np.round(grouped['GVI'].mean(),3).reset_index()\n",
    "    nr_of_points = grouped['GVI'].count().reset_index(name='nr_of_points')\n",
    "    # Merge with the buffered_points dataframe to get the buffer geometries\n",
    "    result = avg_gvi.merge(buffered_points, left_on='id', right_on='id')\n",
    "    result = result.merge(nr_of_points, on='id')\n",
    "    # Convert the result to a GeoDataFrame\n",
    "    result = gpd.GeoDataFrame(result[['id', 'geometry', 'GVI', 'nr_of_points']])\n",
    "\n",
    "    return result, grouped_gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top level function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_streetview_GVI(point_of_interest_file, access_token=None, crs_epsg=None, polygon_type=\"neighbourhood\", buffer_dist=None,\n",
    "                       network_file=None, write_to_file=True, output_dir=os.getcwd()):\n",
    "    \n",
    "    ### Step 1: Read and process user inputs, check conditions\n",
    "    poi = gpd.read_file(point_of_interest_file)\n",
    "    # Make sure geometries of poi file are either all provided using point geometries or all using polygon geometries\n",
    "    if all(poi['geometry'].geom_type == 'Point') or all(poi['geometry'].geom_type == 'Polygon'):\n",
    "        geom_type = poi.iloc[0]['geometry'].geom_type\n",
    "    else:\n",
    "        raise ValueError(\"Please make sure all geometries are of 'Point' type or all geometries are of 'Polygon' type and re-run the function\")\n",
    "\n",
    "    # Make sure CRS of poi file is projected rather than geographic\n",
    "    if not poi.crs.is_projected:\n",
    "        if crs_epsg is None:\n",
    "            print(\"Warning: The CRS of the PoI dataset is currently geographic, therefore it will now be projected to CRS with EPSG:3395\")\n",
    "            epsg = 3395\n",
    "            poi.to_crs(f\"EPSG:{epsg}\", inplace=True)\n",
    "        else:\n",
    "            print(f\"Warning: The CRS of the PoI dataset is currently geographic, therefore it will now be projected to EPSG:{crs_epsg} as specified\")\n",
    "            epsg = crs_epsg\n",
    "            poi.to_crs(f\"EPSG:{epsg}\", inplace=True)\n",
    "    else:\n",
    "        epsg = poi.crs.to_epsg()\n",
    "\n",
    "    # In case of house polygons, transform to centroids\n",
    "    if geom_type == \"Polygon\":\n",
    "        if polygon_type not in [\"neighbourhood\", \"house\"]:\n",
    "            raise TypeError(\"Please make sure that the polygon_type argument is set to either 'neighbourhood' or 'house'\")\n",
    "        if polygon_type == \"house\":\n",
    "            print(\"Changing geometry type to Point by computing polygon centroids...\")\n",
    "            poi['geometry'] = poi['geometry'].centroid\n",
    "            geom_type = poi.iloc[0]['geometry'].geom_type\n",
    "            print(\"Done \\n\")\n",
    "\n",
    "    # Make sure poi dataframe has id column\n",
    "    if \"id\" in poi.columns:\n",
    "        if poi['id'].isnull().values.any():\n",
    "            poi['id'] = poi['id'].fillna(pd.Series(range(1, len(poi) + 1))).astype(int)\n",
    "    else:\n",
    "        poi['id'] = pd.Series(range(1, len(poi) + 1)).astype(int)\n",
    "\n",
    "    # Make sure buffer distance is set in case geometries of poi file are of point type\n",
    "    if geom_type == \"Point\":\n",
    "        if not isinstance(buffer_dist, int) or (not buffer_dist > 0):\n",
    "            raise TypeError(\"Please make sure that the buffer_dist argument is set to a positive integer\")\n",
    "\n",
    "    # Make sure Mapillary API token is provided\n",
    "    if access_token is None:\n",
    "        raise TypeError(\"Please make sure that an access token for Mapillary is provided\")\n",
    "    \n",
    "    # Determine area of interest by taking bounding box of poi file, incl. buffer if specified\n",
    "    if buffer_dist is None:\n",
    "        poi_polygon = box(*poi.total_bounds)\n",
    "        poi['buffer'] = poi['geometry']\n",
    "    else:\n",
    "        poi_polygon = box(*poi.total_bounds).buffer(buffer_dist)\n",
    "        poi['buffer'] = poi['geometry'].buffer(buffer_dist)\n",
    "    # Transform to 4326 for OSM\n",
    "    polygon_gdf_wgs = gpd.GeoDataFrame(geometry=[poi_polygon], crs=f\"EPSG:{epsg}\").to_crs(\"EPSG:4326\") \n",
    "    # Extract polygon in EPSG 4326\n",
    "    wgs_polygon = polygon_gdf_wgs['geometry'].values[0] \n",
    "\n",
    "    if network_file is not None:\n",
    "        # Make sure network file is either provided as geopackage or shapefile\n",
    "        if os.path.splitext(network_file)[1] not in [\".gpkg\", \".shp\"]:\n",
    "            raise ValueError(\"Please provide the network file in '.gpkg' or '.shp' format\")\n",
    "        elif network_file is not None and (os.path.splitext(network_file)[1] == \".gpkg\"):\n",
    "            network_edges = gpd.read_file(network_file, layer='edges')\n",
    "        else: \n",
    "            network_edges = gpd.read_file(network_file)\n",
    "\n",
    "        # Make sure network file CRS is same as CRS of poi file\n",
    "        if not network_edges.crs.to_epsg() == epsg:\n",
    "            print(\"Adjusting CRS of Network file to match with Point of Interest CRS...\")\n",
    "            network_edges.to_crs(f'EPSG:{epsg}', inplace=True)\n",
    "            print(\"Done \\n\")\n",
    "\n",
    "        # Check if house locations are within network file provided\n",
    "        bbox_network = network_edges.unary_union.envelope\n",
    "        if not all(geom.within(bbox_network) for geom in poi['geometry']):\n",
    "            raise ValueError(\"Not all points of interest are within the network file provided, please make sure they are and re-run the function\")\n",
    "    else:\n",
    "        print(f\"Retrieving network within total bounds of {geom_type}(s) of interest, extended by the buffer_dist in case provided...\")\n",
    "        start_network_retrieval = time()\n",
    "        # Extract network from OpenStreetMap\n",
    "        network_edges = get_road_network_with_points(wgs_polygon, epsg=epsg)\n",
    "        end_network_retrieval = time()\n",
    "        elapsed_network_retrieval = end_network_retrieval - start_network_retrieval\n",
    "        print(f\"Done, running time: {str(timedelta(seconds=elapsed_network_retrieval))} \\n\")\n",
    "\n",
    "    print(\"Computing sample points for roads within area of interest's network...\")\n",
    "    start_sample_points = time()\n",
    "    # Get sample points on network roads\n",
    "    road_points = select_points_on_road_network(network_edges)\n",
    "    # Filter points to maintain the ones that are within the buffers of the poi geometries\n",
    "    buffer_points = select_points_within_buffers(poi, road_points)\n",
    "    end_sample_points = time()\n",
    "    elapsed_sample_points = end_sample_points - start_sample_points\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_sample_points))} \\n\")\n",
    "    \n",
    "    print(\"Downloading StreetView images for road sample points...\")\n",
    "    start_images = time()\n",
    "    # Retrieve features, images, from Mapillary for the road locations\n",
    "    features = get_features_on_points(buffer_points, access_token)\n",
    "    #gvi_per_point = download_images_for_points(features, access_token, epsg)\n",
    "    # Process the features and calculate GVI score for road locations\n",
    "    gvi_per_point = process_data(features, access_token, epsg)\n",
    "    end_images = time()\n",
    "    elapsed_images = end_images - start_images\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_images))} \\n\")\n",
    "    \n",
    "    print(\"Calculating StreetView GVI score...\")\n",
    "    start_calc = time()\n",
    "    # Calculate average GVI for each geometry in poi dataframe\n",
    "    poi, sampled_points_gdf = get_gvi_per_buffer(poi, gvi_per_point)\n",
    "    end_calc = time()\n",
    "    elapsed_calc = end_calc - start_calc\n",
    "    print(f\"Done, running time: {str(timedelta(seconds=elapsed_calc))} \\n\")\n",
    "\n",
    "    print(\"Note: workflow for calculating Streetview GVI based on code by Ilse A. Vázquez Sánchez \\nsource: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility \\n\")\n",
    "    \n",
    "    if write_to_file:\n",
    "        print(\"Writing results to new geopackage file in specified directory...\")\n",
    "        # Create output directory if the one specified by user does not yet exist\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        # Extract filename of poi file to add information when writing to file\n",
    "        input_filename, _ = os.path.splitext(os.path.basename(point_of_interest_file))\n",
    "        poi.to_file(os.path.join(output_dir, f\"{input_filename}_StreetviewGVI_added.gpkg\"), driver=\"GPKG\")\n",
    "        sampled_points_gdf.to_file(os.path.join(output_dir, f\"{input_filename}_StreetviewGVI_sampled_points.gpkg\"), driver=\"GPKG\")\n",
    "        print(\"Done\")\n",
    "\n",
    "    return poi, sampled_points_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving network within total bounds of Point(s) of interest, extended by the buffer_dist in case provided...\n",
      "Done, running time: 0:00:04.616102 \n",
      "\n",
      "Computing sample points for roads within area of interest's network...\n",
      "Done, running time: 0:00:00.522553 \n",
      "\n",
      "Downloading StreetView images for road sample points...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading tiles: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]\n",
      "Downloading images: 100%|██████████| 12/12 [06:28<00:00, 32.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done, running time: 0:06:40.280089 \n",
      "\n",
      "Calculating StreetView GVI score...\n",
      "Done, running time: 0:00:00.151857 \n",
      "\n",
      "Note: workflow for calculating Streetview GVI based on code by Ilse A. Vázquez Sánchez \n",
      "source: https://github.com/Spatial-Data-Science-and-GEO-AI-Lab/StreetView-NatureVisibility \n",
      "\n",
      "Writing results to new geopackage file in specified directory...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "poi, sampled_points_gdf = get_streetview_GVI(point_of_interest_file=test_path+\"Test_multiple_home_locations.gpkg\",\n",
    "                                             access_token=\"MAPILLARY_API_TOKEN\", \n",
    "                                             crs_epsg=None, \n",
    "                                             polygon_type=\"neighbourhood\", \n",
    "                                             buffer_dist=65, \n",
    "                                             write_to_file=True, \n",
    "                                             output_dir=test_results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GVI</th>\n",
       "      <th>nr_of_points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (385981.911 393805.494)</td>\n",
       "      <td>0.324</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388631.230 395322.181)</td>\n",
       "      <td>0.013</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                       geometry    GVI  nr_of_points\n",
       "0   2  POINT (385981.911 393805.494)  0.324             3\n",
       "1   3  POINT (388631.230 395322.181)  0.013             8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>geometry</th>\n",
       "      <th>GVI</th>\n",
       "      <th>is_panoramic</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (385990.438 393837.957)</td>\n",
       "      <td>0.323574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (385988.779 393855.628)</td>\n",
       "      <td>0.323574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>POINT (385988.752 393837.984)</td>\n",
       "      <td>0.323574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388654.098 395336.215)</td>\n",
       "      <td>0.013628</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388653.274 395286.222)</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388645.478 395379.148)</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388694.240 395336.063)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388612.771 395334.892)</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388590.281 395297.803)</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388653.594 395305.607)</td>\n",
       "      <td>0.014712</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388590.693 395307.527)</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>POINT (388606.693 395353.242)</td>\n",
       "      <td>0.010661</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                       geometry       GVI is_panoramic  missing\n",
       "0    2  POINT (385990.438 393837.957)  0.323574        False    False\n",
       "1    2  POINT (385988.779 393855.628)  0.323574        False    False\n",
       "2    2  POINT (385988.752 393837.984)  0.323574        False    False\n",
       "3    3  POINT (388654.098 395336.215)  0.013628        False    False\n",
       "4    3  POINT (388653.274 395286.222)  0.014712        False    False\n",
       "5    3  POINT (388645.478 395379.148)  0.037419        False    False\n",
       "6    3  POINT (388694.240 395336.063)       NaN         None     True\n",
       "7    3  POINT (388612.771 395334.892)  0.010661        False    False\n",
       "8    3  POINT (388590.281 395297.803)  0.001739        False    False\n",
       "9    3  POINT (388653.594 395305.607)  0.014712        False    False\n",
       "10   3  POINT (388590.693 395307.527)  0.001739        False    False\n",
       "11   3  POINT (388606.693 395353.242)  0.010661        False    False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_points_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
